---
title: "Homework 5"
author: Ling Tuo
date: 11/16/2020
output: 
  github_document:
    toc: true
---

This is my solution to HW5. 

```{r setup, include = FALSE}
library(tidyverse)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d()
```

## Problem 1

Load the dataset.

```{r include = FALSE}
raw_df = read_csv("data/homicide-data.csv")
```

This dataset contains `r nrow(raw_df)` rows and `r ncol(raw_df)` columns.

The data contains the location of the killing, whether an arrest was made, basic demographic information of each victim. There are victim info variables -- victim_last, victim_first, victim_race, victim_age and victim_sex, location variables -- city, state, lat and lon, and case info -- uid, reported_date and disposition.

```{r echo = FALSE, message = FALSE}
homicide_df = 
  raw_df %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

```{r echo = FALSE, message = FALSE}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarise(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Prop test for a single city -- Baltimore.

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

Iterate the prop test.

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Make a plot of the estimate proportions and CIs for each city.

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Problem 2

Import datasets and add observations, id and group of each subjects as variables.

```{r message = FALSE}
path_df = 
  tibble(
    path = list.files("data/p2_data"),
    id = substr(path, 1, 6)
    ) %>% 
  mutate(
    path = str_c("data/p2_data/", path),
    data = map(path, read_csv)
    ) %>% 
  unnest(data) %>% 
  separate(id, into = c("group", "id"), sep = "_" ) %>% 
  relocate(id, group)
```

Then, tidy the dataframe.

```{r}
tidy_df = 
  path_df %>% 
  select(-path) %>% 
  pivot_longer(week_1:week_8, names_to = "week", values_to = "observation") %>% 
  mutate(week = substr(week, 6, 6))
```

Make a spaghetti plot of observations on each subject over time. Since the observations are difficult to track due to the large quantity, I add linear smooths lines to help looking for trends.

```{r warning = FALSE}
tidy_df %>% 
  group_by(id, group) %>% 
  ggplot(aes(x = week, y = observation, group = id, color = id)) + 
  geom_point(alpha = .3, size = 0.5) +
  geom_line() +
  geom_smooth(method = "lm", size = 0.5, se = FALSE, lty = 2) +
  labs(
  title = "Observations of control and experimental arm over 8 weeks",
  x = "ID",
  y = "Observations") +
  facet_grid(. ~ group) 
```

The observations of subjects fluctuate in both within the control and experimental group, however, the general trend of experimental group is increasing over time and control group has slightly decrease.



