Homework 5
================
Ling Tuo
11/16/2020

-   [Problem 1](#problem-1)
-   [Problem 2](#problem-2)
-   [Problem 3](#problem-3)

This is my solution to HW5.

Problem 1
---------

Load the dataset.

This dataset contains 52179 rows and 12 columns.

The data contains the location of the killing, whether an arrest was
made, basic demographic information of each victim. There are victim
info variables – victim\_last, victim\_first, victim\_race, victim\_age
and victim\_sex, location variables – city, state, lat and lon, and case
info – uid, reported\_date and disposition.

Prop test for a single city – Baltimore.

    prop.test(
      aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
      aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
      broom::tidy() %>% 
      select(estimate, conf.low, conf.high)

    ## # A tibble: 1 x 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

Iterate the prop test.

    results_df = 
      aggregate_df %>% 
      mutate(
        prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
        tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
      ) %>% 
      select(-prop_tests) %>% 
      unnest(tidy_tests) %>% 
      select(city_state, estimate, conf.low, conf.high)

Make a plot of the estimate proportions and CIs for each city.

    results_df %>%
      mutate(city_state = fct_reorder(city_state, estimate)) %>% 
      ggplot(aes(x = city_state, y = estimate)) +
      geom_point() +
      geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

<img src="p8105_hw5_lt2812_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />

Problem 2
---------

Import datasets and add observations, id and group of each subjects as
variables.

    path_df = 
      tibble(
        path = list.files("data/p2_data"),
        id = substr(path, 1, 6)
        ) %>% 
      mutate(
        path = str_c("data/p2_data/", path),
        data = map(path, read_csv)
        ) %>% 
      unnest(data) %>% 
      separate(id, into = c("group", "id"), sep = "_" ) %>% 
      relocate(id, group)

Then, tidy the dataframe.

    tidy_df = 
      path_df %>% 
      select(-path) %>% 
      pivot_longer(week_1:week_8, names_to = "week", values_to = "observation") %>% 
      mutate(week = substr(week, 6, 6))

Make a spaghetti plot of observations on each subject over time. Since
the observations are difficult to track due to the large quantity, I add
linear smooths lines to help looking for trends.

    tidy_df %>% 
      group_by(id, group) %>% 
      ggplot(aes(x = week, y = observation, group = id, color = id)) + 
      geom_point(alpha = .3, size = 0.5) +
      geom_line() +
      geom_smooth(method = "lm", size = 0.5, se = FALSE, lty = 2) +
      labs(
      title = "Observations of control and experimental arm over 8 weeks",
      x = "ID",
      y = "Observations") +
      facet_grid(. ~ group) 

    ## `geom_smooth()` using formula 'y ~ x'

<img src="p8105_hw5_lt2812_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

The observations of subjects fluctuate in both within the control and
experimental group, however, the general trend of experimental group is
increasing over time and control group has slightly decrease.

Problem 3
---------

    set.seed(1)

For *μ* = 0, generate 5000 datasets from the model *X* ∼ *N*(0, 5) with
sample size of 30.

    sim_mean_sd = function(samp_size = 30, mu, sigma = 5) {
      
      sim_data = 
        tibble(
          x = rnorm(n = samp_size, mean = mu, sd = sigma)
        )
      
      t_test = 
        t.test(sim_data$x, mu=0 ,conf.level = 0.95) %>% 
        broom::tidy() %>% 
        select(estimate, p.value)
      
      return(t_test)
      
    }

    sim_result = 
      rerun(5000, sim_mean_sd(mu = 0)) %>% 
      bind_rows()
